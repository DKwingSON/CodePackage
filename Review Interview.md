# DK的 乱 七 八 糟

## LRU高效率算法

put 和 get 方法的时间复杂度为 O(1)，我们可以总结出 cache
这个数据结构必要的条件：查找快，插入快，删除快，有顺序之分。

Get用hash， put用链表（登记hash）

![](media/b09ffcf992c1a8f2d4a892ff08467f6a.png)

什么是**服务注册与服务发现**？

**服务注册**，就是将提供某个服务的模块信息(通常是这个服务的ip和端口)注册到1个公共的组件上去（比如:
zookeeper\\consul）。

**服务发现**，就是新注册的这个服务模块能够及时的被其他调用者发现。不管是服务新增和服务删减都能实现自动发现。

你可以理解为：

//服务注册

NameServer-\>register(newServer);

//服务发现

NameServer-\>getAllServer();

应用场景：**各个微服务相互独立，每个微服务，由多台机器或者单机器不同的实例组成，各个微服务之间错综复杂的相互关联调用**。

任何情况下，处理器检测到event发生，通过异常表（exception
table）跳转到专门处理这类事件的操作系统子程序（exception handler）。

异步异常由事件产生，同步异常是执行一条指令的直接产物。  
类别包含**中断（异步）**，**陷阱（同步）**，**故障（同步）**，**终止（同步）**。

-   中断——异步发生，处理器IO设备信号的结果。

-   陷阱——有意的异常。最重要的用途是在用户程序和内核之间提供一个像过程一样的接口，叫做系统调用。

-   故障——潜在可恢复的错误造成的结果。如果能被修复，则重新执行引起故障的指令，否则终止。

-   终止——不可恢复的致命错误造成的结果。

编译器并不是把函数模板处理成能够处理任意类的函数；编译器从函数模板通过具体类型产生不同的函数；编译器会对函数模板进行两次编译：在声明的地方对模板代码本身进行编译，在调用的地方对参数替换后的代码进行编译。

字节跳动后台：tcp连接在网络不好的情况下一直重传怎么办（采用同步队列，发一个确认一个）；

![](media/b43b1cb18da44ec34007d6937aff06bf.png)

客户端还必须等待 **2MSL** 个时间，这里为什么客户端还不能直接跑路呢？主要是为了防止发送出去的 **ACK** 服务端没有收到，服务端重发 **FIN** 再次来询问，如果客户端发完就跑路了，那么服务端重发的时候就没人理他了。这个等待的时间长度也很讲究。

主动关闭的一方发出 **FIN** 包（Client），被动关闭（Server）的一方响应 **ACK** 包，此时，被动关闭的一方就进入了 **CLOSE_WAIT** 状态。如果一切正常，稍后被动关闭的一方也会发出 **FIN** 包，然后迁移到 **LAST_ACK** 状态。

**布隆过滤器的原理，使用场景和注意事项**

布隆过滤器是一个 bit 向量或者说 bit 数组，长这样：

![](media/ac07f0907802183ec5c94be4da15cca3.jpg)

果我们要映射一个值到布隆过滤器中，我们需要使用**多个不同的哈希函数**生成**多个哈希值**

![](media/c1c641822c5db3b1bf06f267e41bb263.jpg)

![](media/72657f85f84dc52044fffbf12615388c.jpg)

传统的布隆过滤器并**不支持**删除操作

## 最佳实践

常见的适用常见有，利用布隆过滤器减少磁盘 IO
或者网络请求，因为一旦一个值必定不存在的话，我们可以不用进行后续昂贵的查询请求。另外，既然你使用布隆过滤器来加速查找和判断是否存在，那么性能很低的哈希函数不是个好选择，推荐
MurmurHash、Fnv 这些。

为什么不用hash表？hash表在海量数据情况下可能要频繁处理冲突，捞啊。

STL中的unordered_map怎么避免冲突？**链地址法**

**解决幻读？**一种是采用SERIALIZABLE 数据隔离级别

另一种方案是采用在RR数据隔离级别下，手动给select操作加上x锁（排它锁）或者s锁（共享锁）

**共享锁**（SELECT ... LOCK IN SHARE
MODE）即一个事务获取一条记录共享锁的同时，其他事务也可以获得这条记录的共享锁，但是如果同时有多个事务获得这条记录的共享锁，谁也无法修改这条记录，直到都释放掉共享锁，只剩下一个事务拥有这条记录的锁为止。

**排它锁**（SELECT ... FOR
UPDATE）即一个事务获得了一条记录的排它锁的同时，其他事务就不能获得这条记录的共享锁和排它锁，也无法修改这条记录，直到这个事务释放掉锁为止。

。

C++智能指针：

| **指针类别** | **支持**     |                                       |
|              |              | **备注**                              |
|--------------|--------------|---------------------------------------|
| unique_ptr   | C++ 11       | 拥有独有对象所有权语义的智能指针      |
| shared_ptr   | C++ 11       | 拥有共享对象所有权语义的智能指针      |
| weak_ptr     | C++ 11       | 到 std::shared_ptr 所管理对象的弱引用 |
| auto_ptr     | C++ 17中移除 | 拥有严格对象所有权语义的智能指针      |

主要职能指针分为两个unique_ptr和shared_ptr

std::unique_ptr 是通过指针占有并管理另一对象，并在 unique_ptr
离开作用域时释放该对象的智能指针。在下列两者之一发生时用关联的删除器释放对象：

-   销毁了管理的 unique_ptr 对象

-   通过 operator= 或 reset() 赋值另一指针给管理的 unique_ptr 对象。

>   unique_ptr可以用=号赋值吗？ 不可。

std::shared_ptr 是通过指针保持对象共享所有权的智能指针。多个 shared_ptr
对象可占有同一对象。下列情况之一出现时销毁对象并解分配其内存：

-   最后剩下的占有对象的 shared_ptr 被销毁；

-   最后剩下的占有对象的 shared_ptr 被通过 operator= 或 reset() 赋值为另一指针。

主要解决内存泄漏

shared_ptr都会问维护的对象是不是线程安全的，然后问引用计数是不是线程安全的。引用计数源码使用原子操作实现，肯定是线程安全的。

C++ 中有 4 种存储周期：

automatic

static

dynamic

thread

 thread_local
关键字修饰的变量具有线程（thread）周期，这些变量在线程开始的时候被生成，在线程结束的时候被销毁，并且每一个线程都拥有一个独立的变量实例。

C++引用计数（智能指针相关）

![](media/950849bfe8a36e1d3af350bd8239ce1b.png)

# 在一台内存为2G的机器上，malloc(20G) 会怎样？如果是new(20G) 会怎样？

-   首先，malloc和new申请的都是虚拟内存

-   malloc函数的实质，有一个将可用的内存块连接起来的链表，调用malloc的时候，会沿着链表找一个满足用户需求的内存块。然后将这个内存块一分为二，一块和用户所申请的内存大小相同，另一块返回到链表中。如果用户申请一个大的内存块，空闲链表上可能没有可以满足用户要求的片段，这个时候malloc函数就会请求延时，对链表上的内存进行整理。如果还是不可以的话，
    内存申请失败，返回NULL

-   new的话，底层实现还是malloc，在分配失败的时候会抛出bad_alloc类型的异常

**Functor 仿函数**

      所谓仿函数，是定义了operator()的对象，下面这个例子：

FunctionObject fo;

fo();

其中表达式fo()是调用仿函数fo的operator()。而非调用函数fo().

1.  仿函数是对象，可以拥有成员函数和成员变量，即仿函数拥有状态(states)

2.  每个仿函数都有自己的类型

3.  仿函数通常比一般函数快（很多信息编译期确定）

**函数指针**是指向函数的指针变量，本质是一个指针。而**指针函数**是返回值为指针的一个函数，本质是一个函数。**仿函数**实质上是一个重载了（）运算符的对象；

**Lambda函数：编译器会把一个lambda表达式生成一个匿名类的匿名对象，并在类中重载函数调用运算符。（实质上是一个functor）**

## 惊群效应是什么

惊群效应（thundering
herd）是指多进程（多线程）在同时阻塞等待同一个事件的时候（休眠状态），如果等待的这个事件发生，那么他就会唤醒等待的所有进程（或者线程），但是最终却只能有一个进程（线程）获得这个时间的“控制权”，对该事件进行处理，而其他进程（线程）获取“控制权”失败，只能重新进入休眠状态，这种现象和性能浪费就叫做惊群效应。

单机情况下惊群效应通常发生在Linux，Nginx等系统里多个进程等待fd同时被唤醒的情况，解决办法一般是在内核或者系统里，一般不需要上层开发者去处理。分布式系统因为很高的自由度，惊群效应就需要开发者去了解和提出解决办法。

**Solve:** most unix/linux kernels serialize response to accept(2)s, in other
words, only one thread is waken up if more than one are blocking on accept(2)
against a single open file descriptor.

# 海量数据排序——如果有1TB的数据需要排序，但只有32GB的内存如何排序处理？

**思路：不能内排序，那我就外排序，同时优化思路是IO尽可能小。**

**解决方案：分块，块内做内排序（qsort），产生n块有序块，然后每块按序读到内存，做块间数据归并，最后1TB有序**

扩展：海量数据排序，内存够大，怎么做？

1.  如果是无重复整型，果断位排序，（编程珠玑有介绍）。

2.  如果有重复的整型，果断计数排序，

3.  如果是字符串，果断字典树来排序

**TCP滑动窗口结构**

![](media/9ffbd01c432a202f20518dc1b3d0f38d.png)

接收窗口的结构

**1.  Received and ACK Not Send to
Process：这部分数据属于接收了数据但是还没有被上层的应用程序接收，也是被缓存在窗口内**

**2.  Received  Not ACK: 已经接收并，但是还没有回复ACK，这些包可能输属于Delay
ACK的范畴了**

**3.  Not Received：有空位，还没有被接收的数据。**

接收端的Window
Size通告也是会变化的，接收端根据这个值来确定何时及发送多少数据，从对数据流进行流控

**拥塞控制和流量控制的区别**

拥塞控制：拥塞控制是作用于网络的，它是防止过多的数据注入到网络中，避免出现网络负载过大的情况；常用的方法就是：（
1 ）慢开始、拥塞避免（ 2 ）快重传、快恢复。 

流量控制：流量控制是作用于接收者的，它是控制发送者的发送速度从而使接收者来得及接收，防止分组丢失的。
